{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib_inline import backend_inline\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import matplotlib\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import collections\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"Transposition for parallel computation of multiple attention heads.\n",
    "\n",
    "    Defined in :numref:`sec_multihead-attention`\"\"\"\n",
    "    # Shape of input `X`:\n",
    "    # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`).\n",
    "    # Shape of output `X`:\n",
    "    # (`batch_size`, no. of queries or key-value pairs, `num_heads`,\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # Shape of output `X`:\n",
    "    # (`batch_size`, `num_heads`, no. of queries or key-value pairs,\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # Shape of `output`:\n",
    "    # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"Reverse the operation of `transpose_qkv`.\n",
    "\n",
    "    Defined in :numref:`sec_multihead-attention`\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "#@save\n",
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"Mask irrelevant entries in sequences.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    #   X: (b_s * n_q, n_k), valid_len: (b_s * n_q)\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"Perform softmax operation by masking elements on the last axis.\n",
    "\n",
    "    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n",
    "    # `X`: 3D tensor, `valid_lens`: 1D or 2D tensor\n",
    "    # X: (batch_size, no. of que, no. of key) valid_lens: (b_s, ) or (b_s, n_q)\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # On the last axis, replace masked elements with a very large negative\n",
    "        # value, whose exponentiation outputs 0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, # (b_s * n_q, n_k), (b_s * n_q)\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"Scaled dot product attention.\n",
    "\n",
    "    Defined in :numref:`subsec_additive-attention`\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Shape of `queries`: (`batch_size`, no. of queries, `d`)\n",
    "    # Shape of `keys`: (`batch_size`, no. of key-value pairs, `d`)\n",
    "    # Shape of `values`: (`batch_size`, no. of key-value pairs, value\n",
    "    # dimension)\n",
    "    # Shape of `valid_lens`: (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # Set `transpose_b=True` to swap the last two dimensions of `keys`\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d) # (batch_size, no. of que, no. of key)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens) \n",
    "        return torch.bmm(self.dropout(self.attention_weights), values) # (batch_size, no. of que, d_v)\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head attention.\n",
    "\n",
    "    Defined in :numref:`sec_multihead-attention`\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # Shape of `queries`, `keys`, or `values`:\n",
    "        # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`)\n",
    "        # Shape of `valid_lens`:\n",
    "        # (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "        # After transposing, shape of output `queries`, `keys`, or `values`:\n",
    "        # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # On axis 0, copy the first item (scalar or vector) for\n",
    "            # `num_heads` times, then copy the next item, and so on\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # Shape of `output`: (`batch_size` * `num_heads`, no. of queries,\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # Shape of `output_concat`:\n",
    "        # (`batch_size`, no. of queries, `num_hiddens`)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "#@save\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding.\n",
    "\n",
    "    Defined in :numref:`sec_self-attention-and-positional-encoding`\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough `P`\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError\n",
    "#@save\n",
    "class TransformerEncoder(Encoder):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head attention.\n",
    "\n",
    "    Defined in :numref:`sec_multihead-attention`\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # Shape of `queries`, `keys`, or `values`:\n",
    "        # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`)\n",
    "        # Shape of `valid_lens`:\n",
    "        # (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "        # After transposing, shape of output `queries`, `keys`, or `values`:\n",
    "        # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # On axis 0, copy the first item (scalar or vector) for\n",
    "            # `num_heads` times, then copy the next item, and so on\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # Shape of `output`: (`batch_size` * `num_heads`, no. of queries,\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # Shape of `output_concat`:\n",
    "        # (`batch_size`, no. of queries, `num_hiddens`)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # print(f\"in DecoderBlock, X.shape={X.shape}\")\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "\n",
    "\n",
    "        \n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "            key_values = X \n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "            # q, key_values = X, X\n",
    "\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding.\n",
    "\n",
    "    Defined in :numref:`sec_self-attention-and-positional-encoding`\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough `P`\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # print(f'pre: X.shape={X.shape}')\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        # print(f'after psenc: X.shape={X.shape}')\n",
    "        return self.dropout(X)\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"The base decoder interface for the encoder-decoder architecture.\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError\n",
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"The base attention-based decoder interface.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_attention`\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError\n",
    "class TransformerDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # print(f'in transdecoder, X.shape={X.shape}')\n",
    "        \n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        \n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"The base class for the encoder-decoder architecture.\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)\n",
    "\n",
    "def use_svg_display():\n",
    "    \"\"\"Use the svg format to display a plot in Jupyter.\n",
    "\n",
    "    Defined in :numref:`sec_calculus`\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"Set the axes for matplotlib.\n",
    "\n",
    "    Defined in :numref:`sec_calculus`\"\"\"\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        use_svg_display()\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "\n",
    "        return self.data[idx]\n",
    "def grad_clipping(net, theta):\n",
    "    \"\"\"Clip the gradient.\n",
    "\n",
    "    Defined in :numref:`sec_rnn_scratch`\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"Truncate or pad sequences.\n",
    "\n",
    "    Defined in :numref:`sec_machine_translation`\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "def bleu(pred_seq, label_seq, k):\n",
    "    \"\"\"Compute the BLEU.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_training`\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device, save_path=None, from_scrach=True):\n",
    "    \"\"\"Train a model for sequence to sequence.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    if from_scrach:\n",
    "        net.apply(xavier_init_weights)\n",
    "    \n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    # epoches = []\n",
    "    losses = []\n",
    "    # animator = Animator(xlabel='epoch', ylabel='loss',\n",
    "    #                         xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        timer = time.time()\n",
    "        # metric = Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        sum_loss, sum_tokens = 0, 0\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = torch.concat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                sum_loss += l.sum()\n",
    "                sum_tokens += num_tokens\n",
    "        losses.append(sum_loss / sum_tokens)\n",
    "        print(f'epoch: {epoch}, loss {losses[-1]:.3f}, {sum_tokens / (time.time()-timer):.1f} '\n",
    "          f'tokens/sec on {str(device)}')\n",
    "            #     metric.add(l.sum(), num_tokens)\n",
    "        # if (epoch + 1) % 10 == 0:\n",
    "        #     animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    if save_path is not None:\n",
    "        torch.save(net, save_path)\n",
    "    return losses\n",
    "    # print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "    #       f'tokens/sec on {str(device)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(src_vocab)=184\n",
      "len(tgt_vocab)=201\n",
      "epoch: 0, loss 0.404, 6416.4 tokens/sec on cpu\n",
      "epoch: 1, loss 0.314, 7560.7 tokens/sec on cpu\n",
      "epoch: 2, loss 0.277, 6802.6 tokens/sec on cpu\n",
      "epoch: 3, loss 0.248, 7424.2 tokens/sec on cpu\n",
      "epoch: 4, loss 0.231, 7024.6 tokens/sec on cpu\n",
      "epoch: 5, loss 0.219, 7485.3 tokens/sec on cpu\n",
      "epoch: 6, loss 0.210, 7304.2 tokens/sec on cpu\n",
      "epoch: 7, loss 0.198, 6980.4 tokens/sec on cpu\n",
      "epoch: 8, loss 0.195, 7642.7 tokens/sec on cpu\n",
      "epoch: 9, loss 0.188, 7563.6 tokens/sec on cpu\n",
      "epoch: 10, loss 0.182, 7013.0 tokens/sec on cpu\n",
      "epoch: 11, loss 0.175, 7136.6 tokens/sec on cpu\n",
      "epoch: 12, loss 0.174, 7739.9 tokens/sec on cpu\n",
      "epoch: 13, loss 0.171, 7613.2 tokens/sec on cpu\n",
      "epoch: 14, loss 0.167, 7510.4 tokens/sec on cpu\n",
      "epoch: 15, loss 0.162, 7600.6 tokens/sec on cpu\n",
      "epoch: 16, loss 0.155, 7485.3 tokens/sec on cpu\n",
      "epoch: 17, loss 0.153, 7588.4 tokens/sec on cpu\n",
      "epoch: 18, loss 0.149, 7578.1 tokens/sec on cpu\n",
      "epoch: 19, loss 0.149, 7344.2 tokens/sec on cpu\n",
      "epoch: 20, loss 0.144, 7611.6 tokens/sec on cpu\n",
      "epoch: 21, loss 0.139, 7780.6 tokens/sec on cpu\n",
      "epoch: 22, loss 0.140, 7677.7 tokens/sec on cpu\n",
      "epoch: 23, loss 0.138, 7583.6 tokens/sec on cpu\n",
      "epoch: 24, loss 0.131, 7566.4 tokens/sec on cpu\n",
      "epoch: 25, loss 0.130, 7676.2 tokens/sec on cpu\n",
      "epoch: 26, loss 0.128, 7561.2 tokens/sec on cpu\n",
      "epoch: 27, loss 0.125, 7901.9 tokens/sec on cpu\n",
      "epoch: 28, loss 0.126, 7625.3 tokens/sec on cpu\n",
      "epoch: 29, loss 0.124, 7573.0 tokens/sec on cpu\n",
      "epoch: 30, loss 0.122, 7602.8 tokens/sec on cpu\n",
      "epoch: 31, loss 0.121, 7619.8 tokens/sec on cpu\n",
      "epoch: 32, loss 0.115, 7604.3 tokens/sec on cpu\n",
      "epoch: 33, loss 0.116, 7493.9 tokens/sec on cpu\n",
      "epoch: 34, loss 0.114, 7506.8 tokens/sec on cpu\n",
      "epoch: 35, loss 0.112, 7499.4 tokens/sec on cpu\n",
      "epoch: 36, loss 0.112, 7725.5 tokens/sec on cpu\n",
      "epoch: 37, loss 0.109, 7534.0 tokens/sec on cpu\n",
      "epoch: 38, loss 0.111, 7812.3 tokens/sec on cpu\n",
      "epoch: 39, loss 0.108, 7598.8 tokens/sec on cpu\n",
      "epoch: 40, loss 0.107, 7622.5 tokens/sec on cpu\n",
      "epoch: 41, loss 0.106, 7701.2 tokens/sec on cpu\n",
      "epoch: 42, loss 0.102, 7831.9 tokens/sec on cpu\n",
      "epoch: 43, loss 0.104, 7508.3 tokens/sec on cpu\n",
      "epoch: 44, loss 0.104, 7693.6 tokens/sec on cpu\n",
      "epoch: 45, loss 0.103, 7466.8 tokens/sec on cpu\n",
      "epoch: 46, loss 0.101, 7340.7 tokens/sec on cpu\n",
      "epoch: 47, loss 0.101, 7630.9 tokens/sec on cpu\n",
      "epoch: 48, loss 0.100, 7718.1 tokens/sec on cpu\n",
      "epoch: 49, loss 0.101, 6524.7 tokens/sec on cpu\n",
      "epoch: 50, loss 0.097, 6107.5 tokens/sec on cpu\n",
      "epoch: 51, loss 0.099, 7489.0 tokens/sec on cpu\n",
      "epoch: 52, loss 0.096, 7764.5 tokens/sec on cpu\n",
      "epoch: 53, loss 0.095, 7451.7 tokens/sec on cpu\n",
      "epoch: 54, loss 0.093, 7479.3 tokens/sec on cpu\n",
      "epoch: 55, loss 0.093, 7882.7 tokens/sec on cpu\n",
      "epoch: 56, loss 0.093, 7582.0 tokens/sec on cpu\n",
      "epoch: 57, loss 0.092, 7577.3 tokens/sec on cpu\n",
      "epoch: 58, loss 0.090, 7466.0 tokens/sec on cpu\n",
      "epoch: 59, loss 0.093, 7551.2 tokens/sec on cpu\n",
      "epoch: 60, loss 0.090, 7578.5 tokens/sec on cpu\n",
      "epoch: 61, loss 0.092, 7692.3 tokens/sec on cpu\n",
      "epoch: 62, loss 0.093, 7832.1 tokens/sec on cpu\n",
      "epoch: 63, loss 0.091, 7582.1 tokens/sec on cpu\n",
      "epoch: 64, loss 0.091, 7717.0 tokens/sec on cpu\n",
      "epoch: 65, loss 0.086, 7817.8 tokens/sec on cpu\n",
      "epoch: 66, loss 0.090, 7590.8 tokens/sec on cpu\n",
      "epoch: 67, loss 0.088, 7450.4 tokens/sec on cpu\n",
      "epoch: 68, loss 0.088, 7742.9 tokens/sec on cpu\n",
      "epoch: 69, loss 0.087, 8004.4 tokens/sec on cpu\n",
      "epoch: 70, loss 0.087, 7932.4 tokens/sec on cpu\n",
      "epoch: 71, loss 0.084, 8118.0 tokens/sec on cpu\n",
      "epoch: 72, loss 0.087, 8178.9 tokens/sec on cpu\n",
      "epoch: 73, loss 0.087, 8062.3 tokens/sec on cpu\n",
      "epoch: 74, loss 0.088, 8232.7 tokens/sec on cpu\n",
      "epoch: 75, loss 0.087, 8189.0 tokens/sec on cpu\n",
      "epoch: 76, loss 0.086, 8091.7 tokens/sec on cpu\n",
      "epoch: 77, loss 0.087, 8312.8 tokens/sec on cpu\n",
      "epoch: 78, loss 0.086, 7829.3 tokens/sec on cpu\n",
      "epoch: 79, loss 0.087, 8215.4 tokens/sec on cpu\n",
      "epoch: 80, loss 0.086, 7957.3 tokens/sec on cpu\n",
      "epoch: 81, loss 0.083, 7921.6 tokens/sec on cpu\n",
      "epoch: 82, loss 0.083, 7524.2 tokens/sec on cpu\n",
      "epoch: 83, loss 0.085, 7190.0 tokens/sec on cpu\n",
      "epoch: 84, loss 0.083, 7096.4 tokens/sec on cpu\n",
      "epoch: 85, loss 0.081, 7108.5 tokens/sec on cpu\n",
      "epoch: 86, loss 0.083, 7385.0 tokens/sec on cpu\n",
      "epoch: 87, loss 0.080, 7481.5 tokens/sec on cpu\n",
      "epoch: 88, loss 0.081, 7334.6 tokens/sec on cpu\n",
      "epoch: 89, loss 0.081, 7474.8 tokens/sec on cpu\n",
      "epoch: 90, loss 0.078, 7505.1 tokens/sec on cpu\n",
      "epoch: 91, loss 0.084, 7045.3 tokens/sec on cpu\n",
      "epoch: 92, loss 0.080, 7632.6 tokens/sec on cpu\n",
      "epoch: 93, loss 0.081, 7486.8 tokens/sec on cpu\n",
      "epoch: 94, loss 0.080, 7215.3 tokens/sec on cpu\n",
      "epoch: 95, loss 0.079, 7554.9 tokens/sec on cpu\n",
      "epoch: 96, loss 0.079, 7213.4 tokens/sec on cpu\n",
      "epoch: 97, loss 0.077, 6340.6 tokens/sec on cpu\n",
      "epoch: 98, loss 0.080, 7111.2 tokens/sec on cpu\n",
      "epoch: 99, loss 0.077, 7632.3 tokens/sec on cpu\n",
      "epoch: 100, loss 0.075, 7410.8 tokens/sec on cpu\n",
      "epoch: 101, loss 0.076, 7606.7 tokens/sec on cpu\n",
      "epoch: 102, loss 0.076, 7157.5 tokens/sec on cpu\n",
      "epoch: 103, loss 0.078, 7207.2 tokens/sec on cpu\n",
      "epoch: 104, loss 0.077, 7407.7 tokens/sec on cpu\n",
      "epoch: 105, loss 0.076, 6793.4 tokens/sec on cpu\n",
      "epoch: 106, loss 0.075, 7161.9 tokens/sec on cpu\n",
      "epoch: 107, loss 0.077, 7125.6 tokens/sec on cpu\n",
      "epoch: 108, loss 0.078, 7070.5 tokens/sec on cpu\n",
      "epoch: 109, loss 0.072, 7176.2 tokens/sec on cpu\n",
      "epoch: 110, loss 0.077, 7161.8 tokens/sec on cpu\n",
      "epoch: 111, loss 0.076, 6746.7 tokens/sec on cpu\n",
      "epoch: 112, loss 0.075, 6921.0 tokens/sec on cpu\n",
      "epoch: 113, loss 0.076, 6897.2 tokens/sec on cpu\n",
      "epoch: 114, loss 0.074, 6765.5 tokens/sec on cpu\n",
      "epoch: 115, loss 0.074, 7085.7 tokens/sec on cpu\n",
      "epoch: 116, loss 0.078, 6735.1 tokens/sec on cpu\n",
      "epoch: 117, loss 0.073, 6773.5 tokens/sec on cpu\n",
      "epoch: 118, loss 0.074, 5430.2 tokens/sec on cpu\n",
      "epoch: 119, loss 0.073, 6921.3 tokens/sec on cpu\n",
      "epoch: 120, loss 0.075, 7179.8 tokens/sec on cpu\n",
      "epoch: 121, loss 0.072, 6796.7 tokens/sec on cpu\n",
      "epoch: 122, loss 0.073, 7466.0 tokens/sec on cpu\n",
      "epoch: 123, loss 0.073, 6818.3 tokens/sec on cpu\n",
      "epoch: 124, loss 0.072, 6534.4 tokens/sec on cpu\n",
      "epoch: 125, loss 0.074, 6517.5 tokens/sec on cpu\n",
      "epoch: 126, loss 0.075, 6480.1 tokens/sec on cpu\n",
      "epoch: 127, loss 0.073, 6245.2 tokens/sec on cpu\n",
      "epoch: 128, loss 0.073, 6481.7 tokens/sec on cpu\n",
      "epoch: 129, loss 0.070, 6447.9 tokens/sec on cpu\n",
      "epoch: 130, loss 0.071, 5757.0 tokens/sec on cpu\n",
      "epoch: 131, loss 0.073, 6246.3 tokens/sec on cpu\n",
      "epoch: 132, loss 0.072, 6338.9 tokens/sec on cpu\n",
      "epoch: 133, loss 0.073, 6665.1 tokens/sec on cpu\n",
      "epoch: 134, loss 0.069, 7041.0 tokens/sec on cpu\n",
      "epoch: 135, loss 0.070, 6806.7 tokens/sec on cpu\n",
      "epoch: 136, loss 0.068, 7401.3 tokens/sec on cpu\n",
      "epoch: 137, loss 0.068, 6901.6 tokens/sec on cpu\n",
      "epoch: 138, loss 0.072, 5782.1 tokens/sec on cpu\n",
      "epoch: 139, loss 0.070, 5545.3 tokens/sec on cpu\n",
      "epoch: 140, loss 0.070, 6647.4 tokens/sec on cpu\n",
      "epoch: 141, loss 0.069, 6690.7 tokens/sec on cpu\n",
      "epoch: 142, loss 0.071, 6631.6 tokens/sec on cpu\n",
      "epoch: 143, loss 0.069, 6587.1 tokens/sec on cpu\n",
      "epoch: 144, loss 0.070, 6654.4 tokens/sec on cpu\n",
      "epoch: 145, loss 0.068, 6152.8 tokens/sec on cpu\n",
      "epoch: 146, loss 0.069, 5660.3 tokens/sec on cpu\n",
      "epoch: 147, loss 0.068, 5903.0 tokens/sec on cpu\n",
      "epoch: 148, loss 0.070, 4680.4 tokens/sec on cpu\n",
      "epoch: 149, loss 0.073, 6070.1 tokens/sec on cpu\n"
     ]
    }
   ],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 150, torch.device('cpu')\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "from getData_Train import load_data\n",
    "train_iter, src_vocab, tgt_vocab = load_data(batch_size, num_steps, data_path=r'data\\fra-eng\\fra.txt')\n",
    "# train_iter, src_vocab, tgt_vocab = load_data(batch_size, num_steps)\n",
    "print(f'len(src_vocab)={len(src_vocab)}')\n",
    "print(f'len(tgt_vocab)={len(tgt_vocab)}')\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "losses = train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device, 'from_d2l_transformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25fcd4c0730>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"378.465625pt\" height=\"248.518125pt\" viewBox=\"0 0 378.465625 248.518125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-07-19T22:06:00.311004</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nL 0 248.518125 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m3f64187c2b\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3f64187c2b\" x=\"49.641098\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(46.459848 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m3f64187c2b\" x=\"90.495277\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g transform=\"translate(84.132777 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m3f64187c2b\" x=\"131.349457\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g transform=\"translate(124.986957 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m3f64187c2b\" x=\"172.203636\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g transform=\"translate(165.841136 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m3f64187c2b\" x=\"213.057815\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g transform=\"translate(206.695315 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m3f64187c2b\" x=\"253.911995\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g transform=\"translate(244.368245 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m3f64187c2b\" x=\"294.766174\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g transform=\"translate(285.222424 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m3f64187c2b\" x=\"335.620353\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140 -->\n      <g transform=\"translate(326.076603 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path id=\"m5acdc6ee70\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5acdc6ee70\" x=\"36.465625\" y=\"195.665817\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.10 -->\n      <g transform=\"translate(7.2 199.465036)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m5acdc6ee70\" x=\"36.465625\" y=\"166.294458\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.15 -->\n      <g transform=\"translate(7.2 170.093677)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m5acdc6ee70\" x=\"36.465625\" y=\"136.923098\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.20 -->\n      <g transform=\"translate(7.2 140.722317)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m5acdc6ee70\" x=\"36.465625\" y=\"107.551739\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.25 -->\n      <g transform=\"translate(7.2 111.350957)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m5acdc6ee70\" x=\"36.465625\" y=\"78.180379\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.30 -->\n      <g transform=\"translate(7.2 81.979598)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m5acdc6ee70\" x=\"36.465625\" y=\"48.80902\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.35 -->\n      <g transform=\"translate(7.2 52.608238)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m5acdc6ee70\" x=\"36.465625\" y=\"19.43766\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.40 -->\n      <g transform=\"translate(7.2 23.236879)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 51.683807 17.083636 \nL 53.726516 69.904432 \nL 55.769225 91.69505 \nL 57.811934 108.634248 \nL 59.854643 118.795089 \nL 61.897352 126.046581 \nL 63.940061 131.135296 \nL 65.98277 138.182388 \nL 68.025479 139.773221 \nL 70.068188 144.086127 \nL 72.110897 147.645492 \nL 74.153605 151.457785 \nL 76.196314 152.298281 \nL 78.239023 153.79169 \nL 80.281732 156.092629 \nL 82.324441 159.337276 \nL 84.36715 163.31366 \nL 86.409859 164.282384 \nL 88.452568 166.877856 \nL 90.495277 167.117278 \nL 92.537986 169.648606 \nL 94.580695 172.750634 \nL 96.623404 172.212575 \nL 98.666113 173.473582 \nL 100.708822 177.604619 \nL 102.751531 177.950928 \nL 104.79424 178.941002 \nL 106.836949 180.703261 \nL 108.879658 180.180432 \nL 110.922367 181.458596 \nL 112.965076 182.934467 \nL 115.007785 183.415288 \nL 117.050494 186.601494 \nL 119.093203 186.217764 \nL 123.178621 188.466101 \nL 125.22133 188.836293 \nL 127.264039 190.345633 \nL 129.306748 189.303722 \nL 131.349457 190.886279 \nL 133.392166 191.77375 \nL 135.434875 192.230548 \nL 137.477584 194.343081 \nL 139.520292 193.202699 \nL 141.563001 193.185087 \nL 143.60571 193.881434 \nL 145.648419 194.912464 \nL 147.691128 194.90031 \nL 149.733837 195.639513 \nL 151.776546 195.197228 \nL 153.819255 197.668416 \nL 155.861964 196.519959 \nL 159.947382 198.894896 \nL 161.990091 199.69503 \nL 164.0328 199.970612 \nL 166.075509 199.814072 \nL 168.118218 200.611309 \nL 170.160927 201.252185 \nL 172.203636 200.009538 \nL 174.246345 201.634387 \nL 176.289054 200.363585 \nL 178.331763 199.968752 \nL 180.374472 200.673191 \nL 182.417181 200.941389 \nL 184.45989 203.931265 \nL 186.502599 201.385433 \nL 188.545308 202.641889 \nL 190.588017 202.584909 \nL 192.630726 203.387534 \nL 194.673435 203.32921 \nL 196.716144 204.962847 \nL 198.758853 203.504063 \nL 200.801562 203.342099 \nL 202.844271 202.884763 \nL 204.886979 203.576532 \nL 206.929688 203.89714 \nL 208.972397 203.046604 \nL 211.015106 203.713093 \nL 213.057815 203.473794 \nL 215.100524 203.901473 \nL 217.143233 205.875196 \nL 219.185942 205.393398 \nL 221.228651 204.463237 \nL 223.27136 205.918236 \nL 225.314069 206.871436 \nL 227.356778 205.926687 \nL 229.399487 207.312662 \nL 233.484905 206.767486 \nL 235.527614 208.340151 \nL 237.570323 205.351745 \nL 239.613032 207.144041 \nL 241.655741 206.70672 \nL 243.69845 207.695489 \nL 245.741159 208.148698 \nL 247.783868 208.132058 \nL 249.826577 209.013831 \nL 251.869286 207.286025 \nL 253.911995 208.932915 \nL 255.954704 210.133161 \nL 257.997413 209.587963 \nL 260.040122 209.718458 \nL 262.082831 208.681409 \nL 264.12554 208.929851 \nL 266.168249 209.653771 \nL 268.210958 210.077651 \nL 272.296375 208.409215 \nL 274.339084 211.950872 \nL 276.381793 208.960575 \nL 278.424502 209.859207 \nL 280.467211 210.45538 \nL 282.50992 209.547873 \nL 284.552629 210.964344 \nL 286.595338 210.773254 \nL 288.638047 208.641188 \nL 290.680756 211.257996 \nL 292.723465 210.82987 \nL 294.766174 211.57029 \nL 296.808883 210.564552 \nL 298.851592 212.243321 \nL 300.894301 211.248587 \nL 302.93701 211.355518 \nL 304.979719 211.947743 \nL 309.065137 210.501996 \nL 311.107846 211.486818 \nL 313.150555 211.811274 \nL 315.193264 213.201822 \nL 317.235973 212.687173 \nL 319.278682 211.378539 \nL 321.321391 211.887612 \nL 323.3641 211.66508 \nL 325.406809 213.639616 \nL 327.449518 213.130241 \nL 329.492227 214.343403 \nL 331.534936 214.538274 \nL 333.577645 212.194968 \nL 335.620353 213.260338 \nL 337.663062 213.128158 \nL 339.705771 213.901853 \nL 341.74848 212.938989 \nL 343.791189 213.747759 \nL 345.833898 213.123527 \nL 347.876607 214.756364 \nL 349.919316 213.68435 \nL 351.962025 214.614796 \nL 354.004734 213.437991 \nL 356.047443 211.656086 \nL 356.047443 211.656086 \n\" clip-path=\"url(#p452915cae1)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p452915cae1\">\n   <rect x=\"36.465625\" y=\"7.2\" width=\"334.8\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, num_epochs+1), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss 0.030, 7611.7 tokens/sec on cpu\n",
      "epoch: 1, loss 0.030, 8652.0 tokens/sec on cpu\n",
      "epoch: 2, loss 0.030, 8091.6 tokens/sec on cpu\n",
      "epoch: 3, loss 0.031, 8141.6 tokens/sec on cpu\n",
      "epoch: 4, loss 0.032, 8258.6 tokens/sec on cpu\n",
      "epoch: 5, loss 0.030, 7835.3 tokens/sec on cpu\n",
      "epoch: 6, loss 0.030, 8457.5 tokens/sec on cpu\n",
      "epoch: 7, loss 0.030, 8044.9 tokens/sec on cpu\n",
      "epoch: 8, loss 0.029, 8357.0 tokens/sec on cpu\n",
      "epoch: 9, loss 0.032, 8009.0 tokens/sec on cpu\n",
      "epoch: 10, loss 0.030, 7775.8 tokens/sec on cpu\n",
      "epoch: 11, loss 0.030, 7730.2 tokens/sec on cpu\n",
      "epoch: 12, loss 0.030, 7672.0 tokens/sec on cpu\n",
      "epoch: 13, loss 0.029, 7744.6 tokens/sec on cpu\n",
      "epoch: 14, loss 0.029, 7501.6 tokens/sec on cpu\n",
      "epoch: 15, loss 0.031, 7439.2 tokens/sec on cpu\n",
      "epoch: 16, loss 0.030, 7657.4 tokens/sec on cpu\n",
      "epoch: 17, loss 0.031, 7798.3 tokens/sec on cpu\n",
      "epoch: 18, loss 0.030, 8029.7 tokens/sec on cpu\n",
      "epoch: 19, loss 0.028, 7587.4 tokens/sec on cpu\n",
      "epoch: 20, loss 0.031, 7987.8 tokens/sec on cpu\n",
      "epoch: 21, loss 0.030, 7687.5 tokens/sec on cpu\n",
      "epoch: 22, loss 0.030, 7594.0 tokens/sec on cpu\n",
      "epoch: 23, loss 0.030, 7694.6 tokens/sec on cpu\n",
      "epoch: 24, loss 0.031, 7792.5 tokens/sec on cpu\n",
      "epoch: 25, loss 0.031, 7858.4 tokens/sec on cpu\n",
      "epoch: 26, loss 0.029, 7788.3 tokens/sec on cpu\n",
      "epoch: 27, loss 0.031, 7694.7 tokens/sec on cpu\n",
      "epoch: 28, loss 0.029, 7636.4 tokens/sec on cpu\n",
      "epoch: 29, loss 0.029, 7760.9 tokens/sec on cpu\n",
      "epoch: 30, loss 0.029, 7928.4 tokens/sec on cpu\n",
      "epoch: 31, loss 0.031, 7712.9 tokens/sec on cpu\n",
      "epoch: 32, loss 0.029, 7762.5 tokens/sec on cpu\n",
      "epoch: 33, loss 0.028, 8114.0 tokens/sec on cpu\n",
      "epoch: 34, loss 0.030, 8039.1 tokens/sec on cpu\n",
      "epoch: 35, loss 0.030, 8035.8 tokens/sec on cpu\n",
      "epoch: 36, loss 0.029, 8224.8 tokens/sec on cpu\n",
      "epoch: 37, loss 0.030, 8469.5 tokens/sec on cpu\n",
      "epoch: 38, loss 0.029, 8095.6 tokens/sec on cpu\n",
      "epoch: 39, loss 0.029, 8162.9 tokens/sec on cpu\n",
      "epoch: 40, loss 0.030, 8212.3 tokens/sec on cpu\n",
      "epoch: 41, loss 0.030, 8339.1 tokens/sec on cpu\n",
      "epoch: 42, loss 0.030, 8115.1 tokens/sec on cpu\n",
      "epoch: 43, loss 0.031, 8188.1 tokens/sec on cpu\n",
      "epoch: 44, loss 0.029, 8278.4 tokens/sec on cpu\n",
      "epoch: 45, loss 0.030, 7839.8 tokens/sec on cpu\n",
      "epoch: 46, loss 0.031, 7907.1 tokens/sec on cpu\n",
      "epoch: 47, loss 0.030, 7650.6 tokens/sec on cpu\n",
      "epoch: 48, loss 0.030, 7642.2 tokens/sec on cpu\n",
      "epoch: 49, loss 0.029, 8335.4 tokens/sec on cpu\n",
      "epoch: 50, loss 0.031, 8304.5 tokens/sec on cpu\n",
      "epoch: 51, loss 0.031, 8295.6 tokens/sec on cpu\n",
      "epoch: 52, loss 0.030, 8252.9 tokens/sec on cpu\n",
      "epoch: 53, loss 0.030, 8276.6 tokens/sec on cpu\n",
      "epoch: 54, loss 0.029, 8355.1 tokens/sec on cpu\n",
      "epoch: 55, loss 0.030, 8090.9 tokens/sec on cpu\n",
      "epoch: 56, loss 0.029, 7880.3 tokens/sec on cpu\n",
      "epoch: 57, loss 0.030, 7214.4 tokens/sec on cpu\n",
      "epoch: 58, loss 0.029, 7814.6 tokens/sec on cpu\n",
      "epoch: 59, loss 0.031, 8169.4 tokens/sec on cpu\n",
      "epoch: 60, loss 0.029, 8062.4 tokens/sec on cpu\n",
      "epoch: 61, loss 0.030, 7763.4 tokens/sec on cpu\n",
      "epoch: 62, loss 0.029, 7400.0 tokens/sec on cpu\n",
      "epoch: 63, loss 0.030, 8195.2 tokens/sec on cpu\n",
      "epoch: 64, loss 0.029, 8385.0 tokens/sec on cpu\n",
      "epoch: 65, loss 0.031, 7763.6 tokens/sec on cpu\n",
      "epoch: 66, loss 0.029, 8142.9 tokens/sec on cpu\n",
      "epoch: 67, loss 0.031, 8142.8 tokens/sec on cpu\n",
      "epoch: 68, loss 0.030, 8166.5 tokens/sec on cpu\n",
      "epoch: 69, loss 0.030, 7815.2 tokens/sec on cpu\n",
      "epoch: 70, loss 0.030, 7536.6 tokens/sec on cpu\n",
      "epoch: 71, loss 0.031, 5764.2 tokens/sec on cpu\n",
      "epoch: 72, loss 0.030, 8391.7 tokens/sec on cpu\n",
      "epoch: 73, loss 0.029, 8492.1 tokens/sec on cpu\n",
      "epoch: 74, loss 0.031, 8738.8 tokens/sec on cpu\n",
      "epoch: 75, loss 0.028, 8919.8 tokens/sec on cpu\n",
      "epoch: 76, loss 0.029, 8761.3 tokens/sec on cpu\n",
      "epoch: 77, loss 0.030, 8516.1 tokens/sec on cpu\n",
      "epoch: 78, loss 0.030, 8487.8 tokens/sec on cpu\n",
      "epoch: 79, loss 0.031, 8385.4 tokens/sec on cpu\n",
      "epoch: 80, loss 0.030, 7960.7 tokens/sec on cpu\n",
      "epoch: 81, loss 0.031, 7778.2 tokens/sec on cpu\n",
      "epoch: 82, loss 0.029, 7591.3 tokens/sec on cpu\n",
      "epoch: 83, loss 0.030, 7703.3 tokens/sec on cpu\n",
      "epoch: 84, loss 0.032, 6848.5 tokens/sec on cpu\n",
      "epoch: 85, loss 0.032, 6793.2 tokens/sec on cpu\n",
      "epoch: 86, loss 0.029, 5666.7 tokens/sec on cpu\n",
      "epoch: 87, loss 0.030, 6777.1 tokens/sec on cpu\n",
      "epoch: 88, loss 0.029, 7034.4 tokens/sec on cpu\n",
      "epoch: 89, loss 0.029, 6874.3 tokens/sec on cpu\n",
      "epoch: 90, loss 0.030, 6970.3 tokens/sec on cpu\n",
      "epoch: 91, loss 0.028, 7671.9 tokens/sec on cpu\n",
      "epoch: 92, loss 0.031, 7933.8 tokens/sec on cpu\n",
      "epoch: 93, loss 0.032, 7283.5 tokens/sec on cpu\n",
      "epoch: 94, loss 0.031, 7278.6 tokens/sec on cpu\n",
      "epoch: 95, loss 0.028, 7204.0 tokens/sec on cpu\n",
      "epoch: 96, loss 0.029, 6803.7 tokens/sec on cpu\n",
      "epoch: 97, loss 0.030, 6777.9 tokens/sec on cpu\n",
      "epoch: 98, loss 0.031, 6909.9 tokens/sec on cpu\n",
      "epoch: 99, loss 0.029, 6952.2 tokens/sec on cpu\n",
      "epoch: 100, loss 0.030, 5246.5 tokens/sec on cpu\n",
      "epoch: 101, loss 0.029, 6158.8 tokens/sec on cpu\n",
      "epoch: 102, loss 0.030, 7226.7 tokens/sec on cpu\n",
      "epoch: 103, loss 0.029, 7693.4 tokens/sec on cpu\n",
      "epoch: 104, loss 0.028, 7363.7 tokens/sec on cpu\n",
      "epoch: 105, loss 0.029, 7866.1 tokens/sec on cpu\n",
      "epoch: 106, loss 0.030, 7988.5 tokens/sec on cpu\n",
      "epoch: 107, loss 0.028, 6957.2 tokens/sec on cpu\n",
      "epoch: 108, loss 0.030, 6769.9 tokens/sec on cpu\n",
      "epoch: 109, loss 0.029, 7427.9 tokens/sec on cpu\n",
      "epoch: 110, loss 0.030, 7622.3 tokens/sec on cpu\n",
      "epoch: 111, loss 0.029, 7209.9 tokens/sec on cpu\n",
      "epoch: 112, loss 0.028, 7590.4 tokens/sec on cpu\n",
      "epoch: 113, loss 0.029, 7445.1 tokens/sec on cpu\n",
      "epoch: 114, loss 0.028, 7451.4 tokens/sec on cpu\n",
      "epoch: 115, loss 0.030, 7456.1 tokens/sec on cpu\n",
      "epoch: 116, loss 0.028, 7175.2 tokens/sec on cpu\n",
      "epoch: 117, loss 0.028, 7658.9 tokens/sec on cpu\n",
      "epoch: 118, loss 0.030, 7511.4 tokens/sec on cpu\n",
      "epoch: 119, loss 0.031, 7323.1 tokens/sec on cpu\n",
      "epoch: 120, loss 0.029, 7262.4 tokens/sec on cpu\n",
      "epoch: 121, loss 0.030, 7488.5 tokens/sec on cpu\n",
      "epoch: 122, loss 0.029, 7794.6 tokens/sec on cpu\n",
      "epoch: 123, loss 0.029, 7836.2 tokens/sec on cpu\n",
      "epoch: 124, loss 0.028, 7440.8 tokens/sec on cpu\n",
      "epoch: 125, loss 0.029, 7554.4 tokens/sec on cpu\n",
      "epoch: 126, loss 0.029, 7534.8 tokens/sec on cpu\n",
      "epoch: 127, loss 0.029, 8140.9 tokens/sec on cpu\n",
      "epoch: 128, loss 0.028, 7113.1 tokens/sec on cpu\n",
      "epoch: 129, loss 0.029, 7531.1 tokens/sec on cpu\n",
      "epoch: 130, loss 0.030, 7271.9 tokens/sec on cpu\n",
      "epoch: 131, loss 0.030, 7044.9 tokens/sec on cpu\n",
      "epoch: 132, loss 0.031, 7460.3 tokens/sec on cpu\n",
      "epoch: 133, loss 0.028, 7716.8 tokens/sec on cpu\n",
      "epoch: 134, loss 0.029, 7228.1 tokens/sec on cpu\n",
      "epoch: 135, loss 0.029, 7960.7 tokens/sec on cpu\n",
      "epoch: 136, loss 0.028, 7744.0 tokens/sec on cpu\n",
      "epoch: 137, loss 0.030, 7416.1 tokens/sec on cpu\n",
      "epoch: 138, loss 0.028, 7909.5 tokens/sec on cpu\n",
      "epoch: 139, loss 0.030, 7841.1 tokens/sec on cpu\n",
      "epoch: 140, loss 0.029, 7636.6 tokens/sec on cpu\n",
      "epoch: 141, loss 0.029, 7544.3 tokens/sec on cpu\n",
      "epoch: 142, loss 0.031, 7437.6 tokens/sec on cpu\n",
      "epoch: 143, loss 0.030, 7494.1 tokens/sec on cpu\n",
      "epoch: 144, loss 0.030, 7474.4 tokens/sec on cpu\n",
      "epoch: 145, loss 0.027, 7267.8 tokens/sec on cpu\n",
      "epoch: 146, loss 0.029, 7215.6 tokens/sec on cpu\n",
      "epoch: 147, loss 0.030, 6755.7 tokens/sec on cpu\n",
      "epoch: 148, loss 0.030, 7224.3 tokens/sec on cpu\n",
      "epoch: 149, loss 0.028, 7339.5 tokens/sec on cpu\n"
     ]
    }
   ],
   "source": [
    "update_model = torch.load('from_d2l_transformer.pth')\n",
    "lr =  0.001\n",
    "losses = train_seq2seq(update_model, train_iter, lr, num_epochs, tgt_vocab, device, r'from_d2l_transformer.pth', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3])\n",
      "go . => va !,  bleu 1.000\n",
      "tensor([4])\n",
      "i lost . => j'ai perdu .,  bleu 1.000\n",
      "tensor([4])\n",
      "he's calm . => il est paresseux .,  bleu 0.658\n",
      "tensor([4])\n",
      "i'm home . => je suis chez moi .,  bleu 1.000\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_training`\"\"\"\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    print(enc_valid_len)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # Add the batch axis\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "\n",
    "\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    # print(enc_outputs.shape)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)  #TODO: dec_state = ()\n",
    "    # Add the batch axis\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # print(f'dec_X.shape={dec_X.shape}')\n",
    "        # print(f'Y.shape={Y.shape}')\n",
    "        \n",
    "        # We use the token with the highest prediction likelihood as the input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        update_model, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{eng} => {translation}, ',\n",
    "          f'bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
